{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Computational Social Science]\n",
    "## 5-2 Exploratory Data Analysis and Unsupervised Methods - Student Version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This lab will demonstrate some exploratory methods for finding separating words, and introduce unsupervised topic models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Virtual Environment\n",
    "Remember to always activate your virtual environment first before you install packages or run a notebook! This helps to prevent conflicts between dependencies across different projects and ensures that you are using the correct versions of packages. You must have created anaconda virtual enviornment in the `Anaconda Installation` lab. If you have not or want to create a new virtual environment, follow the instruction in the `Anaconda Installation` lab. \n",
    "\n",
    "<br>\n",
    "\n",
    "If you have already created a virtual enviornment, you can run the following command to activate it: \n",
    "\n",
    "<br>\n",
    "\n",
    "`conda activate <virtual_env_name>`\n",
    "\n",
    "<br>\n",
    "\n",
    "For example, if your virtual environment was named as CSS, run the following command. \n",
    "\n",
    "<br>\n",
    "\n",
    "`conda activate CSS`\n",
    "\n",
    "<br>\n",
    "\n",
    "To deactivate your virtual environment after you are done working with the lab, run the following command. \n",
    "\n",
    "<br>\n",
    "\n",
    "`conda deactivate`\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download libraries\n",
    "# ----------\n",
    "#!pip install scattertext\n",
    "#!pip install wordcloud\n",
    "#!pip install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load libraries\n",
    "# ----------\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import spacy\n",
    "import en_core_web_sm\n",
    "import scattertext as st\n",
    "nlp = en_core_web_sm.load()\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from string import punctuation\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "from textblob import TextBlob\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# settings \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"../../images/cfpb_logo.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll once again use the Consumer Financial Protection Bureau's [Consumer Complaint Database](https://www.consumerfinance.gov/data-research/consumer-complaints/). This time, we are going to focus on figuring out whether we can find text features that help distinguish different \"Products.\" There are several products represented in the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "# ----------\n",
    "\n",
    "# load the dataframe\n",
    "cfpb = pd.read_csv(\"../../data/CFPB 2020 Complaints.csv\")\n",
    "\n",
    "# drop missing on \"Consumer complaint narrative\" feature and reset the index bc we've dropped\n",
    "cfpb = cfpb.dropna(subset = ['Consumer complaint narrative'])# not reseting the index here bc doing some other cleaning\n",
    "\n",
    "# identify the unique characters is Product column\n",
    "cfpb['Product'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the first few exercises, we will focus on mortgages and student loans. We will also just use the first one thousand observations so that the code runs faster. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out only columns where product == \"Mortgage\" or \"Student loan\"\n",
    "cfpb = cfpb[(cfpb['Product']=='Mortgage') | (cfpb['Product'] == 'Student loan')]\n",
    "\n",
    "# subset the first 1000 rows \n",
    "cfpb = cfpb[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view \n",
    "# ----------\n",
    "cfpb.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by creating our tokens. We'll use the same `rem_punc_stop()` function we defined last time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create preprocessing function - just like we did in the last lab\n",
    "# ----------\n",
    "def rem_punc_stop(text):\n",
    "\n",
    "    # set objects\n",
    "    stop_words = STOP_WORDS         # set STOP_WORDS to a new object variable\n",
    "    punc = set(punctuation)         # convert punctuation to a set\n",
    "    \n",
    "    # essentially remove the punctuation - important to remove punctuation first to correctly capture stop words\n",
    "    punc_free = \"\".join([ch for ch in text if ch not in punc]) # join new list of characters (ch) in text w/ condition\n",
    "                                                               # if ch is not in punctuation \n",
    "                                                               # \"\".join() creates a string from the list comprehension\n",
    "\n",
    "    # apply nlp to punctuation-free object\n",
    "    doc = nlp(punc_free)\n",
    "    \n",
    "    # extract words from processed text \n",
    "    spacy_words = [token.text for token in doc]\n",
    "    \n",
    "    # filter out words \n",
    "    no_punc = [word for word in spacy_words if word not in stop_words]\n",
    "    \n",
    "    # return\n",
    "    return no_punc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice here how we use the `map()` function to apply our `rem_punc_stop()` function to every row of our dataframe. `map()` is typically much faster than writing a for loop, though there are also faster options like [list comprehensions](https://docs.python.org/3/tutorial/datastructures.html) and vectorized numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now apply the function to all the columns in our dataframe\n",
    "# ----------\n",
    "cfpb['tokens'] = cfpb['Consumer complaint narrative'].map(lambda x: rem_punc_stop(x)) # can use apply here \n",
    "cfpb['tokens'] # visualize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Cloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the most popular text analysis visualizations is the word cloud. Word clouds visualize the most frequent words in a corpus, and size them according to frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now apply the function to all the columns in our dataframe\n",
    "# ----------\n",
    "# apply function to text object\n",
    "text = ' '.join(cfpb['tokens'].map(lambda text: ' '.join(text)))\n",
    "\n",
    "# create WordCloud visualization using the \"text\" object \n",
    "wordcloud = WordCloud(random_state=40)...\n",
    "\n",
    "# plot \n",
    "plt.imshow(wordcloud,                  # specify wordcloud\n",
    "           interpolation = 'bilinear') # specifies how the words are displayed\n",
    "plt.axis('off')                        # turn off axes\n",
    "plt.show()                             # show the plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are lots of ways to customize a word cloud, including by changing the background color:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same word cloud as above but changing background parameters\n",
    "# ----------\n",
    "# apply function to text object\n",
    "text = ' '.join(cfpb['tokens'].map(lambda text: ' '.join(text)))\n",
    "\n",
    "# create WordCloud visualization using the \"text\" object \n",
    "wordcloud = WordCloud(...,             # set background color to white\n",
    "                      random_state=41  # set random state to ensure same word cloud each time\n",
    "                      )...)            # change the background color\n",
    "\n",
    "\n",
    "\n",
    "# plot \n",
    "plt.imshow(wordcloud,                  # specify wordcloud\n",
    "           interpolation = 'bilinear') # specifies how the words are displayed \n",
    "plt.axis('off')                        # turn off axes\n",
    "plt.show()                             # show the plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can even overlay the wordcloud onto an image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spread the word cloud over the CFPB logo\n",
    "# ----------\n",
    "# load image\n",
    "cfpb_mask = np.array(Image.open(\"../../images/cfpb_logo.png\"))\n",
    "\n",
    "# create word cloud\n",
    "text = ' '.join(cfpb['tokens'].map(lambda text: ' '.join(text)))\n",
    "\n",
    "# specify parameters of the wordcloud\n",
    "wordcloud = WordCloud(...                        # set background color to white\n",
    "                      random_state=77,           # set random state to ensure same word cloud each time\n",
    "                      mask = cfpb_mask,          # mask is necessary \n",
    "                      contour_width=0.0001,      # provides an outline for clarity\n",
    "                      width = 1000,\n",
    "                      height = 1000).generate(text)\n",
    "\n",
    "# plot \n",
    "plt.imshow(wordcloud,                   # specify wordcloud\n",
    "           interpolation = 'bilinear')  # specifies how the words are displayed\n",
    "plt.axis('off')                         # turn off axes\n",
    "plt.show()                              # show the plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge\n",
    "\n",
    "Notice that in the above word clouds, tokens like \"XXXX\" and \"XXXXXXXX\" appear frequently. These are redacted dates and likely won't help us with classification. Try to rewrite `rem_punc_stop` to remove these.\n",
    "\n",
    "**Hint**: Try taking a look at `nlp.Defaults.stop_words` and see if there are any associated methods that might help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rewrite the rem_punc_stop function to remove redacted account numbers (e.g, \"XXX\")\n",
    "# ----------\n",
    "\n",
    "def rem_punc_stop(text):\n",
    "    stop_words = STOP_WORDS\n",
    "\n",
    "    # remove stop words\n",
    "    nlp.Defaults.stop_words ...\n",
    "    \n",
    "    # convert punctuation to set\n",
    "    punc = set(...)\n",
    "    \n",
    "    # essentially remove the punctuation - important to remove punctuation first to correctly capture stop words\n",
    "    punc_free = \"\".join([ch for ch in text if ch not in punc]) # join new list of characters (ch) in text w/ condition\n",
    "                                                               # if ch is not in punctuation \n",
    "                                                               # \"\".join() creates a string from the list comprehension\n",
    "\n",
    "    # apply nlp to punctuation-free object\n",
    "    doc = nlp(...)\n",
    "    \n",
    "    # extract words from processed text \n",
    "    spacy_words = [token.text for token in doc]\n",
    "    \n",
    "    # filter out words \n",
    "    no_punc = [word for word in spacy_words if word not in stop_words]\n",
    "    \n",
    "    # return\n",
    "    return no_punc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recreate word cloud from above \n",
    "# ----------\n",
    "\n",
    "# need to do preprocessing again and re-create \"tokens\" column\n",
    "cfpb['tokens'] = cfpb['Consumer complaint narrative'].map(lambda x: rem_punc_stop(x))\n",
    "\n",
    "# apply function to text object\n",
    "text = ...\n",
    "\n",
    "# create WordCloud visualization using the \"text\" object \n",
    "wordcloud = WordCloud(...                    # specify white background\n",
    "                     random_state=42         # set seeed\n",
    "                     ).generate(...)         # generate from text dataset\n",
    "\n",
    "\n",
    "# plot \n",
    "plt.imshow(wordcloud,                  # specify wordcloud\n",
    "           interpolation = 'bilinear') # specifies how the words are displayed\n",
    "plt.axis('off')                        # turn off axes\n",
    "plt.show()                             # show the plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bonus**: This is an example where using [regular expressions](https://docs.python.org/3/library/re.html) can be useful. Instead of inputting all of the different ways that something like \"XX\" might show up, you can use regex to find and remove all similar patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lengths and Counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the basic things we might look for when analyzing text data is the length of a document. Let's see how we might grab the total number of characters and the total number of words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new feature columns with counts of # of characters and # of words\n",
    "# ----------\n",
    "\n",
    "# count number of characters\n",
    "cfpb['complaint_len'] = cfpb['Consumer complaint narrative'].apply(len)\n",
    "\n",
    "# count number of words\n",
    "cfpb['word_count'] = cfpb['Consumer complaint narrative'].apply(lambda x: len(str(x).split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create histogram of complaint length (number of characters)\n",
    "sns.displot(...,               # specify data\n",
    "            x=\"complaint_len\") # x-axis feature\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create histogram of word count\n",
    "sns.displot(...,            # specify data\n",
    "            x=\"word_count\") # x-axis feature\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram of word count by loan product \n",
    "sns.displot(...,              # specify data\n",
    "            x=\"word_count\",   # x-axis feature\n",
    "            hue = \"Product\",  # color by loan product\n",
    "            col = \"Product\")  # color by loan product\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Polarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A common area of research in the social sciences is thinking about the \"sentiment\" of a text. The [`TextBlob`](https://textblob.readthedocs.io/en/dev/quickstart.html) library gives us access to a pre-trained sentiment analysis model. Text might be characterized as \"positive,\" \"negative,\" or \"neutral\" on a [-1,1] scale with -1 being highly negative and 1 being highly positive. Before we look at the code, do you expect that the sentiment scores for these data should be negative or positive? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a feature colum of sentiment polarity\n",
    "# ---------- \n",
    "# create the \"tokens\" column again \n",
    "cfpb['tokens'] = cfpb['tokens'].map(lambda text: ' '.join(text))\n",
    "\n",
    "# create the \"tokens\" column again \n",
    "cfpb['polarity'] = cfpb['tokens'].map(lambda text: TextBlob(text).sentiment.polarity)\n",
    "\n",
    "# view\n",
    "cfpb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram of polarity\n",
    "sns.displot(...,         # specify data\n",
    "            x=\"...\")     # x-axis label \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's going on here? Why does sentiment look so close to neural, or even slightly positive? We know that all of the narratives in this dataset are consumer **complaints**, so we should expect them to look somewhat negative. Let's look at the 5 most positive reviews:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop to view the 5 most positive reviews\n",
    "# ---------- \n",
    "for complaint in cfpb.nlargest(5, 'polarity')['Consumer complaint narrative']:\n",
    "    print(complaint + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do we have any words that are skewing things? Let's look at the sentiment score for this first comment, and the individual sentiments of the words in it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# focus on the first complaint and view its overall polarity \n",
    "# ---------- \n",
    "# create string capturing the first complaint above for analysis\n",
    "sample_complaint = \"the company said they are offering a covid relief program which I requested assistance and they are saying a balloon payment is owed in XXXX I called the company and I was told that if I can't make this payment they will be talking taking litigation steps how are people who have lost their job able to keep their homes\"\n",
    "\n",
    "# print polarity score\n",
    "print(\"overall polarity score is \", TextBlob(sample_complaint).sentiment.polarity)\n",
    "for word in sample_complaint.split():\n",
    "    print(word, TextBlob(word).sentiment.polarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only one word actually has a sentiment score (\"able\")! TextBlob's sentiment polarity is not a simple average of all of the sentiments in a string - this is why preprocessing is important and why you should validate these types of off-the-shelf methods. Let's take a look at the most negative reviews and see if these make sense:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop to view the 5 most negative reviews\n",
    "# ---------- \n",
    "for complaint in cfpb.nsmallest(5, 'polarity')['Consumer complaint narrative']:\n",
    "    print(complaint + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# focus on the first complaint and view its overall polarity \n",
    "# ---------- \n",
    "# create string capturing the first complaint above for analysis\n",
    "sample_complaint = \"Navient is the worst company to ever exist. Website does not work. Do the people at customer service even work for navient??? They don't know anything about whats going on. Applied for a repayement plan and their website always says an error has occured.\"\n",
    "\n",
    "# print polarity score\n",
    "print(\"overall polarity score is \", TextBlob(sample_complaint).sentiment.polarity)\n",
    "for word in sample_complaint.split():\n",
    "    print(word, TextBlob(word).sentiment.polarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case we have a perfectly negative sentiment (-1.0), but again only one word is contirbuting - \"worst\". Sentiment polarity is a powerful tool, but not automatically suited to inference. That being said, maybe it can be helpful for distinguishing between labels. We can take a look at how polarity differs across mortgage and student loans. \n",
    "\n",
    "Is cutting the data this way helpful or not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram of polarity by loan product\n",
    "sns.displot(...,             # specify data\n",
    "            x=\"polarity\",    # specify x-axix feature \n",
    "            hue = \"Product\", # color by loan product\n",
    "            col = \"Product\") # color by loan product\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge\n",
    "\n",
    "In addition to sentiment polarity, TextBlob also has a method for determining how \"objective\" or \"subjective\" a piece of text is. Plot the objectivity measure by loan product. Do these results make sense?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create measure of subjectivity\n",
    "# ---------- \n",
    "\n",
    "# create new column feature of subjectivity\n",
    "cfpb['subjectivity'] = cfpb[...].map(lambda... .sentiment.subjectivity)\n",
    "\n",
    "# plot\n",
    "sns.displot(...) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ANSWER**: ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ScatterText"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we'll take a look at a useful visualization for finding separarting words. We'll use the [ScatterText](https://spacy.io/universe/project/scattertext) library to visualize both word frequencies and how well they separate two classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create measure of subjectivity\n",
    "# ---------- \n",
    "corpus = st.CorpusFromPandas(cfpb[:5000],              # specify data\n",
    "                             category_col = 'Product', # specify the explanatory variable  \n",
    "                             text_col = 'tokens',      # specify the text column\n",
    "                             nlp = nlp).build()        # apply the nlp algorithim and build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create html document\n",
    "html = st.produce_scattertext_explorer(corpus,\n",
    "                                       category='Student loan',\n",
    "                                       category_name='Student loan',\n",
    "                                       not_category_name='Mortgage',\n",
    "                                       width_in_pixels=1000,\n",
    "                                       minimum_term_frequency=5,\n",
    "                                       metadata=cfpb['Complaint ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write html document to memory and open in browser\n",
    "open(\"CFPB Sentiment.html\", 'wb').write(html.encode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unsupervised Methods\n",
    "\n",
    "Finally, we'll look at unsupervised machine learning methods for text data. In this section, we'll implement K-means clustering algorithm, which is a simple and commonly used unsupervised machine learning methods, and [Latent Dirichlet Allocation (LDA)](https://en.wikipedia.org/wiki/Latent_Dirichlet_allocation), which is a classic method for topic modeling. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and process data\n",
    "# ---------- \n",
    "cfpb = pd.read_csv(\"../../data/CFPB 2020 Complaints.csv\")\n",
    "cfpb = cfpb.dropna(subset = ['Consumer complaint narrative'])\n",
    "cfpb = cfpb[(cfpb['Product']=='Checking or savings account') | (cfpb['Product'] == 'Student loan')]\n",
    "cfpb = cfpb[:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by creating our tf-idf matrix again. Note that this might take a bit because were are working with 1000 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create tf-idf matrix\n",
    "# ----------\n",
    "# set X dataset\n",
    "X = cfpb['Consumer complaint narrative']        \n",
    "\n",
    "# initialize tf-idf using our preprocessing function\n",
    "tf = TfidfVectorizer(tokenizer = ...,           # use our function for tokenizing created above\n",
    "                     token_pattern = None)      # set to \"None\" since we have specify our own pattern\n",
    "\n",
    "# fit and transform data\n",
    "tfidf_matrix =  tf...(...)\n",
    "\n",
    "# create dense matrix to view\n",
    "dense_matrix = tfidf_matrix...()\n",
    "dense_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a useful visualization of tf-idf matrix\n",
    "# ----------\n",
    "\n",
    "# convert matrix to an arrray and then to a dataframe\n",
    "tfidf_df = pd.DataFrame(data = tfidf_matrix.toarray(),      # convert to array than to datafram\n",
    "                        columns=tf....())                   # specify column names as feature names \n",
    "\n",
    "# sort by term frequency on the first document\n",
    "tf_idf_df. .. .nlargest(10,  # transpose the matrix and show just first 10 words \n",
    "                        0)   # on column index 0 to show the largest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Means\n",
    "\n",
    "Now let's implement a simple kmeans clustering algorithim and add those labels (which cluster each record belongs to) back to our dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# K-means clustering\n",
    "# ------------------------------\n",
    "\n",
    "# implement kmeans clustering\n",
    "# ----------\n",
    "kmeans = KMeans(...,                # specify 3 of clusters\n",
    "                ...                 # specify 300 of iterations\n",
    "                ).fit(tfidf_matrix) # specify data to fit\n",
    "\n",
    "\n",
    "# append labels to dataframe\n",
    "# ----------\n",
    "cfpb['cluster']= kmeans. ...   # add labels to original data frame\n",
    "cfpb.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Determining optiminal K: Elbow method\n",
    "\n",
    "However, one of the key steps is to determine the optimal `k`. There are many ways to do this, but one approach is to iterate over a range of `k`s and use the elbow method to determine the best `k`.\n",
    "\n",
    "The [elbow method](https://medium.com/@rohithramesh1991/unsupervised-text-clustering-using-natural-language-processing-nlp-1a8bc18b048d) will calculate the *within-sum of squared distances* of every point from its respective cluster, and this will serve as a measure of compactness. We want that number to be smaller. A steep drop in WSS will create an elbow and indicates the appropriate number of clusters. However, remember this is **not always guaranteed.**\n",
    "\n",
    "Let's see how we can implement this. **Describe what each line is doing:** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# determining optional k: elbow method\n",
    "# ------------------------------\n",
    "\n",
    "# settings\n",
    "# ---------\n",
    "# \n",
    "Sum_of_squared_distances = []\n",
    "\n",
    "# \n",
    "K = range(1, 10) # second number is the ceiling of the range, but remember it is exclusive\n",
    "\n",
    "\n",
    "# loop over k\n",
    "# ---------\n",
    "for k in K:\n",
    "    # \n",
    "    km = KMeans(n_clusters=k,     #\n",
    "                init='k-means++', #\n",
    "                n_init=10)        # \n",
    "    #\n",
    "    km = km.fit(tfidf_matrix)     # \n",
    "\n",
    "    # \n",
    "    Sum_of_squared_distances.append(km.inertia_)\n",
    "\n",
    "\n",
    "# plot results\n",
    "# ---------\n",
    "plt.plot(K, Sum_of_squared_distances, 'bx-')\n",
    "plt.xlabel('k')\n",
    "plt.xticks(range(1, max(K) + 1, 1))\n",
    "plt.ylabel('Sum_of_squared_distances')\n",
    "plt.title('Elbow Method For Optimal k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Determining optiminal K: silhouette scores\n",
    "\n",
    "Another way to determine the optimal `k` is to compare silhouette scores across clusters. Again, there are many ways to do this, but one approach is to iterate over a range of `k`s and compare how far the score for each cluster deviates from the average across clusters. Then select the `k` where each cluster has a value closest to the  average. \n",
    "\n",
    "[Silhouette scores](https://scikit-learn.org/stable/auto_examples/cluster/plot_kmeans_silhouette_analysis.html) quantify how close each point in a cluster is to points in the neighboring clusters and thus provide a way to assess parameters like number of clusters visually. They silhouette score will take a value on a range from -1 to 1, where scores near +1 indicate that the sample is far away from the neighboring clusters, 0 indicates a sample is on or very close to the decision boundary between two neighboring clusters, and negative -1 indicates that sample might have been assigned to the wrong cluster.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# determining optional k: silhouette scores\n",
    "# ------------------------------\n",
    "# define a number of functions\n",
    "\n",
    "# iterate over a k-means fits to have different clusters\n",
    "# ---------\n",
    "def run_KMeans(max_k, data):\n",
    "    max_k += 1\n",
    "    kmeans_results = dict()\n",
    "    for k in range(2 , max_k):\n",
    "        kmeans = KMeans(n_clusters = k\n",
    "                               , init = 'k-means++'\n",
    "                               , n_init = 10\n",
    "                               , random_state = 1)\n",
    "\n",
    "        kmeans_results.update( {k : kmeans.fit(data)} )\n",
    "        \n",
    "    return kmeans_results\n",
    "\n",
    "\n",
    "# calculate average silhouettes scores \n",
    "# ---------\n",
    "# plot silhouettes scores\n",
    "def printAvg(avg_dict):\n",
    "    for avg in sorted(avg_dict.keys(), reverse=True):\n",
    "        print(\"Avg: {}\\tK:{}\".format(avg.round(4), avg_dict[avg]))\n",
    "\n",
    "# plot silhouettes scores       \n",
    "def plotSilhouette(df, n_clusters, kmeans_labels, silhouette_avg): \n",
    "    fig, ax1 = plt.subplots(1)\n",
    "    fig.set_size_inches(8, 6)\n",
    "    ax1.set_xlim([-0.2, 1])   # play with this to set x-axis limits\n",
    "    ax1.set_ylim([0, len(df) + (n_clusters + 1) * 10])\n",
    "    \n",
    "    ax1.axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\") # The vertical line for average silhouette score of all the values\n",
    "    ax1.set_yticks([])  # Clear the yaxis labels / ticks\n",
    "    ax1.set_xticks([-0.2, 0, 0.2, 0.4, 0.6, 0.8, 1])\n",
    "    plt.title((\"Silhouette analysis for K = %d\" % n_clusters), fontsize=10, fontweight='bold')\n",
    "    \n",
    "    y_lower = 10\n",
    "    sample_silhouette_values = silhouette_samples(df, kmeans_labels) # Compute the silhouette scores for each sample\n",
    "    for i in range(n_clusters):\n",
    "        ith_cluster_silhouette_values = sample_silhouette_values[kmeans_labels == i]\n",
    "        ith_cluster_silhouette_values.sort()\n",
    "\n",
    "        size_cluster_i = ith_cluster_silhouette_values.shape[0]\n",
    "        y_upper = y_lower + size_cluster_i\n",
    "\n",
    "        color = cm.nipy_spectral(float(i) / n_clusters)\n",
    "        ax1.fill_betweenx(np.arange(y_lower, y_upper), 0, ith_cluster_silhouette_values, facecolor=color, edgecolor=color, alpha=0.7)\n",
    "\n",
    "        ax1.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i)) # Label the silhouette plots with their cluster numbers at the middle\n",
    "        y_lower = y_upper + 10  # Compute the new y_lower for next plot. 10 for the 0 samples\n",
    "    plt.show()\n",
    "    \n",
    "# put it altogether\n",
    "def silhouette(kmeans_dict, df, plot=True):\n",
    "    df = df.to_numpy()\n",
    "    avg_dict = dict()\n",
    "    for n_clusters, kmeans in kmeans_dict.items():      \n",
    "        kmeans_labels = kmeans.predict(df)\n",
    "        silhouette_avg = silhouette_score(df, kmeans_labels) # Average Score for all Samples\n",
    "        avg_dict.update( {silhouette_avg : n_clusters} )\n",
    "    \n",
    "        if(plot): plotSilhouette(df, n_clusters, kmeans_labels, silhouette_avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**QUESTION:** What do we think about the fit? Are we happy with any set number of clusters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# calculate silhouette scores across potential k-means clusters \n",
    "# ---------\n",
    "\n",
    "# set K\n",
    "k = 8 # choose 8 based on the elbow method result from above\n",
    "\n",
    "# run the k-means algorithm\n",
    "kmeans_results = run_KMeans(k,                # set k\n",
    "                            data = tfidf_df)  # identify data\n",
    "\n",
    "\n",
    "# plot the silhouette analysis\n",
    "silhouette(kmeans_results,     # take k-means results\n",
    "           tfidf_df)           # use the dataframe version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ANSWER:**  Based on the results from the silhouette scores analysis, there does not seem to be an optimal number of clusters that fit the data well in their current form. A k-means clustering fit would likely perform better after more some more cleaning (removing more unhelpful words) or a rethinking of the dataset (perhaps there is no clear distinction between student loans and mortgage complaints using bag-of-word structured analysis. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cluster analysis of top words\n",
    "\n",
    "Still, we might want to evaluate some of the top words in each cluster to confirm k-means is not a good approach here or to validate when it indeed is. We can write a function to iterate over the clusters and pull the top word. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# cluster analysis of top words in each cluster\n",
    "# ------------------------------\n",
    "\n",
    "# create functions\n",
    "# ---------\n",
    "\n",
    "# get the top features from each cluster\n",
    "def get_top_features_cluster(tf_idf_array, prediction, n_feats):\n",
    "    labels = np.unique(prediction)\n",
    "    dfs = []\n",
    "    for label in labels:\n",
    "        id_temp = np.where(prediction==label) # indices for each cluster\n",
    "        x_means = np.mean(tf_idf_array[id_temp], axis = 0) # returns average score across cluster\n",
    "        sorted_means = np.argsort(x_means)[::-1][:n_feats] # indices with top 20 scores\n",
    "        features = tf.get_feature_names_out()\n",
    "        best_features = [(features[i], x_means[i]) for i in sorted_means]\n",
    "        df = pd.DataFrame(best_features, columns = ['features', 'score'])\n",
    "        dfs.append(df)\n",
    "    return dfs\n",
    "\n",
    "# plot them on a barplot\n",
    "def plotWords(dfs, n_feats):\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    for i in range(0, len(dfs)):\n",
    "        plt.title((\"Most Common Words in Cluster {}\".format(i)), fontsize=10, fontweight='bold')\n",
    "        sns.barplot(x = 'score' , y = 'features', orient = 'h' , data = dfs[i][:n_feats])\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**QUESTION:** Do these word plots give us any insight into why these k-means models are not performing well?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run k-means and visualize word count\n",
    "# ---------\n",
    "\n",
    "# get results from 5 clusters \n",
    "best_result = 5\n",
    "kmeans = kmeans_results.get(best_result)\n",
    "\n",
    "# processing for plot\n",
    "tfidf_array = tfidf_df.to_numpy()     # convert dataframe to array\n",
    "prediction = kmeans.predict(tfidf_df) # predict cluster using tf-idf dataframe\n",
    "\n",
    "\n",
    "# plot\n",
    "n_feats = 20\n",
    "dfs = get_top_features_cluster(tfidf_array, # specify dataset which is an array\n",
    "                               prediction,  # make specify prediciton\n",
    "                               n_feats )    # set number of features \n",
    "plotWords(dfs, # specify data for plotting  \n",
    "          13)  # set number of features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ANSWER:** If we look back at the `tfidf_df`, we can see a number of paragraph separators (`\\n`) that seem to remain in the documents, it is likely host black spaces that are showing up here, and would be one thing that might improve fit if we were to remove them. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Latent Dirichlet Allocation (LDA)\n",
    "\n",
    "\n",
    "Now, let's turn to LDA. Remember, like other unsupervised machine learning models, topic models can help us uncover structure within a text. It does so through a \"mixture model\" - meaning every document is assumed to be \"about\" various topics, and we try to estimate the proportion each topic contributes to a document. \n",
    "\n",
    "Let that we have a tf-idf matrix, let's apply our LDA model. The key hyperparameter here is the `n_components` argument. Let's start with 5, and then print out our topics to see what we get."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Fitting a Latent Dirichlet Allocation model \n",
    "# ------------------------------\n",
    "\n",
    "# initialize LDA model \n",
    "# ---------- \n",
    "lda = LatentDirichletAllocation(...,              # set # of components to 5\n",
    "                                ...,              # specify 20 max iterations\n",
    "                                random_state=0)   # set seed for reproducibility\n",
    "\n",
    "# fit LDA to data\n",
    "# ---------- \n",
    "lda = lda.fit(tfidf_matrix)  # use the sparse matrix created above \n",
    "lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to get and view top words for each topic\n",
    "# ---------- \n",
    "def print_top_words(model, feature_names, n_top_words):    # define function and parameters\n",
    "    for topic_idx, topic in enumerate(model.components_):  # iterate over each topic \n",
    "        print(\"\\nTopic #{}:\".format(topic_idx))            # print topic index\n",
    "        print(\" \".join([feature_names[i]                   # print topics\n",
    "                        for i in topic.argsort()[:-n_top_words - 1:-1]]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get feature names from tf-idf matrices \n",
    "# ---------- \n",
    "tf_feature_names = tf....()   # get feature names\n",
    "\n",
    "\n",
    "# apply function to print top words\n",
    "print_top_words(...,                # model \n",
    "                tf_feature_names,   # feature names \n",
    "                ...)                # top 20 words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 5 topics! Some seem to be sensible (i.e. Topic #1 seems to be about banking attitudes while Topic #2 is about loans payments), but notice that the computer doesn't provide a \"topic name\" for us automatically, so there is still a role for humans to interpret and make sense of the output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Topic weights\n",
    "\n",
    "One thing we may want to do with the output is compare the prevalence of each topic across documents. A simple way to do this, is to merge the topic distribution back into the `pandas` dataframe.\n",
    "\n",
    "Let's first get the topic distribution array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate topic weights from distribution \n",
    "# ----------\n",
    "topic_dist = lda.transform(tfidf_matrix) # calculate distribution of topics for each document in the corpus \n",
    "topic_dist  # note that this output is an array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then we'll merge back with original dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert topic distribution array to pandas dataframe\n",
    "# ----------\n",
    "topic_dist_df = pd.DataFrame(topic_dist)\n",
    "\n",
    "# join back to pandas dataframe and reset index\n",
    "df_w_topics = topic_dist_df.join(cfpb.reset_index())\n",
    "\n",
    "# view\n",
    "df_w_topics.head() # notice that the topic distribution is the first 5 columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can check the average weight of each topic across loan product using `groupby`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group by loan products and calculate mean\n",
    "# ----------\n",
    "\n",
    "# group the topds\n",
    "grouped = df_w_topics.groupby('Product')\n",
    "\n",
    "# loop over the dataframe and calculate mean\n",
    "for i in range(0, 5):\n",
    "    print(grouped[i].mean().sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "None of the topics seem to have much separation, but let's visualize topics 2 and 3 to be sure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram of topic 2\n",
    "# ----------\n",
    "sns.displot(df_w_topics,      # data\n",
    "            x=df_w_topics[2], # x-axis feature subet to only topic 2\n",
    "            hue = \"Product\",  # by loan product\n",
    "            kind = 'kde',     # specify kdensity plot\n",
    "            fill = 'true')    # fill\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram of topic 3\n",
    "# ----------\n",
    "sns.displot(df_w_topics,      # data\n",
    "            x=df_w_topics[3], # x-axis feature subet to only topic 2\n",
    "            hue = \"Product\",  # by loan product\n",
    "            kind = 'kde',     # specify kdensity plot\n",
    "            fill = 'true')    # fill\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unsurprisingly, there doesn't seem to be very much separation between the two topics given that we didn't see much separation between the means above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge\n",
    "\n",
    "Try retraining the LDA with a different number of topics, for example, try 10. \n",
    "\n",
    "\n",
    "**QUESTION:** What do you notice? How is this similar to issues we've seen with other clustering algorithms?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LDA - 10 topics instead\n",
    "# ---------- \n",
    "\n",
    "# initialize LDA model \n",
    "lda = LatentDirichletAllocation(...,             # specify 10 components\n",
    "                                ...,             # set max iter to 20\n",
    "                                random_state=0)  # set random seed\n",
    "\n",
    "\n",
    "# fit LDA to data\n",
    "lda = lda.fit(...) # specify a matrix input\n",
    "\n",
    "# define a function to get and view top words for each topic\n",
    "def print_top_words(model, feature_names, n_top_words):   # define function and parameters\n",
    "    for topic_idx, topic in enumerate(model.components_): # iterate over each topic \n",
    "        print(\"\\nTopic #{}:\".format(topic_idx))           # print topic index\n",
    "        print(\" \".join([feature_names[i]                  # print topics\n",
    "                        for i in topic.argsort()[:-n_top_words - 1:-1]]))\n",
    "    print()\n",
    "\n",
    "# get feature names from tf-idf matrices \n",
    "tf_feature_names = tf. ...()\n",
    "\n",
    "# apply function to print top 20 words\n",
    "print_top_words(...,   # model \n",
    "                ...,   # feature names \n",
    "                ...)   # number of top words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ANSWER**: ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Notebook developed by Aniket Kesari. Modified by Prashant Sharma (2023) and annotated by Kasey Zapatka (2024)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
