---
title: '6-7: Sensitivity Analysis and Bounds - Student'
author: ""
date: " `r format(Sys.time(), '%B %d, %Y')`"
output: pdf_document
---

```{r message=FALSE, echo=FALSE}
# Install packages 
# # ----------
if (!require("pacman")) install.packages("pacman")

pacman::p_load(# Tidyverse packages including dplyr and ggplot2 
               tidyverse,
               ggthemes,
               konfound,
               dagitty,
               ggdag,
               sensitivitymv,
               EValue)  

# set dag theme
# ----------
theme_set(theme_dag())

# source functions
# ----------
source("pretty_dag.R")

# set seed
# ----------
set.seed(13)
```

# Sensitivity Analysis Rationale

So far in our explorations of observational studies we have considered various methods of accounting for measured confounders $W$ as well as some cases in which we can account for unmeasured confounders $U$ (e.g. if we have measured a suitable instrumental variable).

However, it is quite often the case that we are simply unable to control for unmeasured confounding in any meaningful way. Another strategy then is to quantify the *uncertainty* due to unmeasured confounding. Doing so is commonly referred to as Sensitivity Analysis. (Note: The term "Sensitivity Analysis" can be used much more broadly to refer to methods of varying *any* modeling assumptions, but here we use the more specific definition)

Recall that we already use methods of quantifying uncertainty due to random variation (e.g. standard error, confidence intervals, hypothesis testing). However, this *random* uncertainty is distinct from the *systematic* uncertainty due to unmeasured confounding.

# Simulation

Let us again consider a version of our AspiTyleCedrin example. Much like in our Instrumental Variables lab, in this version both exposure to AspiTyleCedrin and the outcome of experiencing a migraine are affected by watching cable news, since AspiTyleCedrin ads are commonly shown on cable news channels, and stress from excessive cable news watching can trigger migraines. 
However, in this case we have not been able to measure an instrumental variable such as living near a pharmacy which sells AspiTyleCedrin.

Thus we have the following variables:

**Endogenous variables:**

* `A`: Treatment variable indicating whether the individual $i$ took AspiTyleCedrin ($A_i = 1$) or not ($A_i = 0$).
* `Y`: Outcome variable indicating whether the individual experienced a migraine ($Y_{i_{obs}} = 1$) or not ($Y_{i_{obs}} = 0$).
* `W`: Variable representing sex assigned at birth, with $W = 0$ indicating AMAB (assigned male at birth), $W = 1$ indicating AFAB (assigned female at birth), and $W = 2$ indicating an X on the birth certificate, possibly representing an intersex individual or left blank.


**Exogenous variables:**

* `U`: Unmeasured confounding variable, cable news watching, which affects the exposure $A$ and the outcome $Y$, 

And our DAG is as follows:

```{r out.width="75%", echo=FALSE}
# Create a DAG using dagify
# ----------
dagify(Y ~ A,
       Y ~ U,
       Y ~ W,
       A ~ U,
       A ~ W,
       exposure = "A",
       outcome = "Y") %>%
  tidy_dagitty() %>%
  pretty_dag() %>%
  ggdag() +
  geom_dag_edges() +
  geom_dag_node(aes(color = color)) +
  geom_dag_text(col = "white") +
  theme(legend.position = "none") +
  scale_color_manual(values=c("darkred", "lightgrey", "darkgrey", "navy"))
```

Simulate the dataset:

```{r}

# specify the number of observations we want for our simulated data
# ----------
n = 1e4 # Number of individuals

# NOTE: Again, don't worry too much about how we're creating this dataset, 
# this is just an example.

# create simulated dataframe
# ----------
df <- data.frame(U = rbernoulli(n, p = 0.34),
                 W = sample(0:2, size = n, replace = TRUE, 
                             prob = c(0.49,0.50,0.01)) 
) %>% 

# create 
# ----------
# df <- df %>% 
  mutate(Y_0 = as.numeric(rbernoulli(n,
                                     p = (0.87 + 0.035*(W > 0) + 
                                            0.05*(U > 0)))),
         Y_1 = as.numeric(rbernoulli(n, 
                                     p = (0.34 + 0.035*(W > 0) + 
                                            0.3*(U > 0)))),
         A = as.numeric(rbernoulli(n, 
                                   p = (0.03 + 0.06*(W > 0) + 0.21*(U == 1)))),
         ITE = Y_1 - Y_0,
         Y = as.numeric((A & Y_1) | (!A & Y_0))
)

# summarize
# ----------
head(df)
summary(df)

# calculate ATE "true" as a reference - remember we'd likely not have this in practice
# ----------
ATE_true <- mean(df$ITE)
ATT_true <- mean((df %>% filter(A == 1))$ITE)
ATE_true

# shirk dataframe to only include treatment (A), covariates (W: sex at birth), and outcome (Y)
# ----------
df <- 
  df %>% 
  select(A, W, Y)
```

Recall that the Average Treatment Effect (ATE) is the average difference in the pair of potential outcomes averaged over the entire population of interest (at a particular moment in time), or rather, it is just the average (or expected value) of the individual-level treatment effect.

$$\text{ATE} = E[Y_{i}(1) - Y_{i}(0)]$$

**\textcolor{blue}{QUESTION 1:}** Use the `group_by()` and `summarize()` functions to find the estimated average treatment effect using the following formula. Compare this result to the actual ATE (saved as `ATE_true`).

$$\hat{\text{ATE}} = E[Y_i |A_i = 1, W_i = w_i] - E[Y_i|A_i = 0, W_i = w_i]$$
```{r}

# calculate mean of outcome by treatment
# ----------
est <- ...

# calculate the ATE 
# ----------
ATE_crude <- ...
```

$$\text{ATE} = ATE_{true}$$

$$\hat{\text{ATE}} \approx ATE_{crude}$$


The following code chunk uses the base `R` package `confint()` to estimate the ATE in a similar manner, but also allows us to calculate confidence intervals and p-values for this estimate:

```{r,} 

# estimate the treatment effect assuming no confounding
# ----------
ATE_est <- 
  df %>% 
  # run a linear model 
  lm(Y ~ A, data = .)

# calculate confidence for ATE using confint() package
confint(ATE_est) 
  
# compare to "true" ATE
ATE_true

```

**\textcolor{blue}{QUESTION 2:}** Report the estimate calculated by the `confint()` function call above, as well as the 95% confidence interval and p-value.

$$\hat{\text{ATE}} \approx summary(ate_{out})$Estimate[3,1]$$
$$\text{95\% CI}_{\hat{\text{ATE}}} \approx [summary(ate_{out})$Estimate[3,3], summary(ate_{out})$Estimate[3,4]] $$
$$\text{p-value} \approx summary(ate_{out})$Estimate[3,6]$$


**\textcolor{blue}{QUESTION 3:}** What would you conclude from the information you reported in the previous question if you did not know the true ATE? From what you do know the true ATE and the DAG, do you think the confidence interval appropriately captures the level of uncertainty of that estimate? Explain.

**ANSWER**: 

This is a stark reminder that our interpretation of measures such as p-values, CIs, etc. are only valid if our assumptions are correct! Here we know they are not.

The CI and p-value calculated above account only for the random uncertainty (and systematic uncertainty from measured confounding $W$. Now we will consider different methods of quantifying the uncertainty due to the *unmeasured confounding $U$*.

# Manski Bounds

One method for quantifying the uncertainty due to the unmeasured confounding $U$ is by quantifying logical bounds upon necessary parameters and propagating those bounds through to the parameter of interest.

First, let us consider the ATE in more detail. We can rewrite the formula from above as:

$$\text{ATE} = E[Y_{i}(1) - Y_{i}(0)] = E[Y_{i}(1)] - E[Y_{i}(0)] = \mu_t - \mu_c$$

where $\mu_t$ is simply the average outcome under the counterfactual in which everyone received the treatment ($A = 1$ for everyone) and $\mu_c$ is simply the average outcome under the counterfactual in which no one received the treatment ($A = 0$ for everyone). NOTE: For simplicity we will ignore $W$ for now.

Note that by the definition of expectation we can further break down these $\mu$ values like so:

\begin{align*}
\mu_t &= P(A = 1) \cdot E[Y_{i}(1) | A = 1]  + P(A = 0) \cdot E[Y_{i}(1) | A = 0] \\
\mu_c &= P(A = 1) \cdot E[Y_{i}(0) | A = 1]  + P(A = 0) \cdot E[Y_{i}(0) | A = 0] \\
\end{align*}

Or:

\begin{align*}
\mu_t &= p \cdot \mu_{t,1} + (1-p)\cdot \mu_{t,0} \\
\mu_c  &= p \cdot \mu_{c,1} + (1-p)\cdot \mu_{c,0} \\
\end{align*}

where:

* $p$ is the probability of treatment.
* $\mu_{t,1}$ is the average outcome of treatment among those who actually receive the treatment.
* $\mu_{t,0}$ is the average outcome of treatment among those who *do not* receive the treatment.
* $\mu_{c,1}$ is the average outcome of *not receiving* treatment among those who actually receive the treatment.
* $\mu_{c,0}$ is the average outcome of *not receiving* treatment among those who *do not* receive the treatment.

In practice, we can reasonably estimate $p$, $\mu_{t,1}$ and $\mu_{c,0}$, but *not* $\mu_{t,0}$ and $\mu_{c,1}$.

**\textcolor{blue}{QUESTION 4:}** Explain why the previous statement is true.

**ANSWER**: 

However, we do know that since the outcome $Y$ is binary, $\mu_{t,0}$ and $\mu_{c,1}$ must by definition lie inside the interval [0,1]. This knowledge allows us to construct bounds on $\mu_t$ and $\mu_c$ like so:

\begin{align*}
\mu_t &\in [p \cdot \mu_{t,1} , p \cdot \mu_{t,1} + (1-p) ]\\
\mu_c  &\in [ (1-p) \cdot \mu_{c,0} , (1-p) \cdot \mu_{c,0} + p] \\
\end{align*}

We can see how the bounds for $\mu_t$ and $\mu_c$ above follow from bounds of [0,1] on $\mu_{t,0}$ and $\mu_{c,1}$:

\begin{align*}
LL_{\mu_t} &= \mu_t, [\mu_{t,0} = 0] \\
&= p \cdot \mu_{t,1} + (1-p)\cdot 0 \\
&= p \cdot \mu_{t,1} \\
UL_{\mu_t} &= \mu_t, [\mu_{t,0} = 1] \\
&= p \cdot \mu_{t,1} + (1-p)\cdot 1 \\
& = p \cdot \mu_{t,1} + (1-p) \\
LL_{\mu_c}  &= \mu_c, [\mu_{c,1} = 0] \\
&= p \cdot 0 + (1-p)\cdot \mu_{c,0}  \\
&= (1-p)\cdot \mu_{c,0} \\
UL_{\mu_c}  &= \mu_c, [\mu_{c,1} = 1] \\
&= p \cdot 1 + (1-p)\cdot \mu_{c,0}  \\
&= p + (1-p)\cdot \mu_{c,0} \\
\end{align*}

We can then use these bounds of $\mu_t$ and $\mu_c$ in the formula for the ATE to get bounds for the ATE itself.

\begin{align*}
\text{ATE} &= \mu_t - \mu_c \\
LL_{ATE} &= LL_{\mu_t} - UL_{\mu_c} \\
&= [p \cdot \mu_{t,1}] - [p + (1-p)\cdot \mu_{c,0}]  \\
UL_{ATE} &= UL_{\mu_t} - LL_{\mu_c} \\
&= [p \cdot \mu_{t,1} + (1-p)] - [(1-p)\cdot \mu_{c,0}]  \\
\end{align*}

**\textcolor{blue}{QUESTION 6:}** Why are the bounds for the ATE calculated in this way? For example, why not find the difference of both lower bounds and both upper bounds, respectively?

**ANSWER**: 

We now have a formula for the ATE using only $p$, $\mu_{t,1}$ and $\mu_{c,0}$, which we said earlier can be reasonably estimated from our data. Thus we can use plug-in estimators for these values to estimate the bounds for the ATE, like so:

\begin{align*}
\hat{LL}_{ATE} &= [\hat{p} \cdot \hat{\mu}_{t,1}] - [\hat{p} + (1 - \hat{p}) \cdot \hat{\mu}_{c,0}]  \\
\hat{UL}_{ATE} &= [\hat{p} \cdot \hat{\mu}_{t,1} + (1 - \hat{p})] - [(1 - \hat{p})\cdot \hat{\mu}_{c,0}]  \\
\end{align*}

**\textcolor{blue}{QUESTION 7:}** Calculate these bounds on the ATE using the data.

```{r}

# get necessary statistics   
# ----------
p_hat <- nrow(df %>% filter(... == 1)) / nrow(df) # filter only treated units, calculate % under treatment
mu.t1_hat <- df %>% filter(... == 1) %>% summarise(...(Y)) %>% pull(...) # calculate outcome mean under treatment, pull
mu.c0_hat <- df %>% filter(... == 0) %>% summarise(...(Y)) %>% pull(...) # calculate outcome mean under control, pul...

# calculate lower and upper bounds of ATE
# ----------
LL_ATE <- p_hat*mu.t1_hat - (p_hat + (1 - p_hat)*mu.c0_hat)
UL_ATE <- p_hat*mu.t1_hat + (1 - p_hat) - (1 - p_hat)*mu.c0_hat

LL_ATE
UL_ATE

```

$$ATE \in [`LL_{ATE}`,`UL_{ATE}`]$$
Note that by definition this interval must contain zero and must have a width of one. Do not confuse this with a confidence interval! Also note that this does not include the random variation associated with our estimates.

**\textcolor{blue}{QUESTION 8:}** Compare this interval to the true ATE.

**ANSWER**: 

# Rosenbaum Sensitivity Analysis

While Manski Bounds are useful to estimate a "worst case" range of possible values, since zero is necessarily included they are not especially informative.

It is useful, then, to be able to use outside knowledge or other reasonable assumptions about possible ranges of values to possibly restrict this interval.

The Rosenbaum-Rubin approach incorporates a bit more complexity than do Manski bounds. First, we imagine the unmeasured confounding $U$ as binary with some probability $q$, where:

$$q = P(U_i = 1) = 1 - P(U_i = 0)$$
We then specify models for the relationships between the unmeasured confounding $U$ and the other variables: treatment assignment $A$, outcome under treatment $Y(1)$, and outcome under no treatment $Y(1)$. Note that we are still ignoring the measured confounder $W$ for now. Since $A$, $Y(1)$, and $Y(0)$ are all binary, we can specify logistic models for these relationships, like so:

\begin{align*}
\text{logit}[P(A_i = 1 | U_i = u)] &= \gamma_0 + \gamma_1 \cdot u \\
\text{logit}[P(Y_i(1) = 1 | U_i = u)] &= \alpha_0 + \alpha_1 \cdot u \\
\text{logit}[P(Y_i(0) = 1 | U_i = u)] &= \beta_0 + \beta_1 \cdot u \\
\end{align*}

Or:

\begin{align*}
P(A_i = 1 | U_i = u) &= \text{logit}^{-1}[\gamma_0 + \gamma_1 \cdot u] \\  
&= \frac{e^{\gamma_0 + \gamma_1 \cdot u}}{1 + e^{\gamma_0 + \gamma_1 \cdot u}} \\
P(Y_i(1) = 1 | U_i = u) &= \text{logit}^{-1}[\alpha_0 + \alpha_1 \cdot u]  \\  
&= \frac{e^{\alpha_0 + \alpha_1 \cdot u}}{1 + e^{\alpha_0 + \alpha_1 \cdot u}} \\
P(Y_i(0) = 1 | U_i = u) &= \text{logit}^{-1}[\beta_0 + \beta_1 \cdot u]  \\  
&= \frac{e^{\beta_0 + \beta_1 \cdot u}}{1 + e^{\beta_0 + \beta_1 \cdot u}} \\
\end{align*}

Now we recall that we can write the ATE as:

\begin{align*}
ATE &= \mu_t - \mu_c \\
&= [p \cdot \mu_{t,1} + (1-p)\cdot \mu_{t,0}] - [p \cdot \mu_{c,1} + (1-p)\cdot \mu_{c,0}] \\
&= p \cdot (\mu_{t,1} - \mu_{c,1}) + (1-p)\cdot ( \mu_{t,0} - \mu_{c,0}) \\
\end{align*}

Following the derivations in Chapter 22 of Imbens/Rubin, we can write each of these parameters ($p$, $\mu_{t,1}$, $\mu_{t,0}$, $\mu_{c,1}$, $\mu_{c,0}$) in terms of the parameters seen above ($q$, $\gamma_0$, $\gamma_1$, $\alpha_0$, $\alpha_1$, $\beta_0$, $\beta_1$). 

Chapter 22.4 details the translations of our reasonably estimable values $p$, $\mu_{t,1}$, and $\mu_{c,0}$, and shows that these relationships can allow us to find estimate values for $\gamma_0$, $\alpha_0$, and $\beta_0$.

If we then postulate values for $q$, $\gamma_1$, $\alpha_1$, and $\beta_1$, we can then estimate values for $\mu_{t,0}$ and $\mu_{c,1}$. Our sensitivity analysis then comes down to the decisions we make for postulating $q$, $\gamma_1$, $\alpha_1$, and $\beta_1$.

For example, if we fix $q = p$ and let $\gamma_1 \rightarrow \infty$, $\alpha_1 \rightarrow \infty$, and $\beta_1 \rightarrow \infty$, we find:

$$ATE = p \cdot \mu_{t,1} - p - (1 - p) \cdot \mu_{c,0}$$
which is equivalent to the lower limit derived from the Manski bounds! Furthermore, if we fix $q = p$ and let $\gamma_1 \rightarrow \infty$, $\alpha_1 \rightarrow -\infty$, and $\beta_1 -\rightarrow \infty$, we find:

$$ATE = p \cdot \mu_{t,1} + (1 - p) - (1 - p) \cdot \mu_{c,0}$$
which is equivalent to the upper limit derived from the Manski bounds! Therefore we can see Manski bounds as simply a special case of this type of sensitivity analysis.

## Shiny App

This approach has been implemented via a Shiny App [here](https://carohaensch.shinyapps.io/tippingsens/). This app allows you to upload your data and adjust two of the parameters discussed above ($q$, $\gamma_1$, $\alpha_1$, $\beta_1$) while holding the other two constant.

**\textcolor{blue}{QUESTION 9:}** Upload our data to the app and play around with a few different values/ranges of the four parameters. Take a screesnot of at least one of your iterations and include it below. Discuss what you see and interpret in terms of our original analysis. (Note: You will need to modify the format of our dataset slightly before uploading--read instructions on the app webpage for details)

```{r}
# create dataframe for uploading
# ----------
df.shiny <- 
  df %>% 
  mutate(Treatment = A,
         Outcome = Y) %>%
  select(-W)

# save as .csv
# ----------
write_csv(df.shiny, "df.shiny_new.csv")
```

# E-Value

Another technique we will look at is the `E-Value.` The basic logic of the E-value is that it is the necessary strength of association between an unobserved confounder would need with both the treatment and outcome to erase an effect estimate. A small E-value implies only a small amount of confounding is necessary to erase the results, whereas a large E-value implies a large amount of confounding would be necessary.

To run the E-value calculation, we can use the [`EValue`](https://cran.r-project.org/web/packages/EValue/index.html) package. THe main function we will look at is `evalues.RR()` which evaluates the E-Value using a risk ratio (the probability of an outcome occurring in the exposed group relative to the probability of an outcome in the unexposed group). To run this analysis we simply need this one line:

```{r}

# calculate Evalue's Risk Ratio: prob outcome in treatment / prob outcome in control
# ----------
evalues.RR(est = 0.3434709, lo = 0.3152002, hi =0.3717417)
```

Using our ATE estimates from earlier, we see that we get an E-value of 5.27. This E-value implies that a confounder would need to be associated with a 5.27-fold increase in the individual experiencing a migraine, AND be 5.27 times more prevalent among people who received the drug. 

We can use the `bias_plot()` function to get a sense of the range of values for which unobserved confounding would invalidate our inference.  

```{r}

# look at a range of values
# ----------
bias_plot(0.3434709, xmax = 20)
```


In the example above, we see that if the exposure-confounder parameter ($RR_{EU}$) were about 3.5, meaning that the confounder(s) is 3.5 times more likely among the treatment group (people who receive the drug), the ($RR_{UD}$) parameter would have to be about 20 (migraine) for it to even be possible that confounding explains the entire observed association (remember in the E-value literature, E is exposure or treatment and D is outcome).


**\textcolor{blue}{QUESTION 10:}**  Do you find this figure to be reassuring?

**ANSWER**: ...


# Konfound

Finally, another similar sensitivity option is `konfound`. The logic is similar to that of the E-value--what would the correlational strength of a possible confounder need to be to invalidate inference? To get at this, the output returns an estimate of the percent of the estimate that would have to be due to bias to invalidate the inference. One added bonus with this method is that it will give you the number of observations that would have to be replaced with a case that has a null effect to invalidate inference, which is a very intuitive way to explain sensitivity to readers.  

Take a look at the [documentation](https://cran.r-project.org/web/packages/konfound/konfound.pdf) and a useful [tutorial](https://cran.r-project.org/web/packages/konfound/vignettes/introduction-to-konfound.html).


```{r}

#
# before we have conducted an analysis
# ------------------------------------------------


# estimate a model 
# ---------
ATE_est <- 
  df %>% 
  # run a linear model 
  lm(Y ~ A, data = .)

# konfound
# ---------
konfound(ATE_est, A)

```

We can use `pkonfound()` when we have values from an already-conducted analysis. One noteable application is that this would allow you to estimate sensativity for models you might encounter in a paper. 

```{r}

#
# when we already conducted an analysis
# ------------------------------------------------

# pkonfound
# ---------
pkonfound(est_eff = -0.3244, 
          std_err = 0.010019, 
          n_obs = 10000, 
          n_covariates = 1)

# threshold plot 
# share "above threshold" represents share of estimate not confounded
pkonfound(est_eff = -0.3244, 
          std_err = 0.010019, 
          n_obs = 10000, 
          n_covariates = 1,
          to_return = "thresh_plot") 

# correlation plot 
# 0.697 represents the correlation needed of a confounder with treatment & outcome
pkonfound(est_eff = -0.3244, 
          std_err = 0.010019, 
          n_obs = 1000,
          to_return = "corr_plot") 

```

# References

* Imbens, G. W., &amp; Rubin, D. B. (2018). Causal inference for statistics, social, and biomedical sciences: An introduction. New York: Cambridge University Press.

* Frank, Kenneth, Spiro J. Maroulis, Minh Q. Duong, and Benjamin M. Kelcey. 2013. “What Would It Take to Change an Inference? Using Rubin’s Causal Model to Interpret the Robustness of Causal Inferences.” Educational Evaluation and Policy Analysis 35(4):437–60. doi: 10.3102/0162373713493129.

* Crosnoe, Robert. 2009. “Low-Income Students and the Socioeconomic Composition of Public High Schools.” American Sociological Review 74(5):709–30.

* https://carohaensch.shinyapps.io/tippingsens/