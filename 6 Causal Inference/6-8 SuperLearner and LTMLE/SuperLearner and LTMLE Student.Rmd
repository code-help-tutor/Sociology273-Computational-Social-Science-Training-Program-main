---
title: "SuperLearner and LTMLE"
output:
  pdf_document: default
  html_document: default
urlcolor: blue
---

```{r, echo = FALSE}
knitr::opts_chunk$set(message = FALSE, warning = FALSE, warning = FALSE)
```

```{r}
# Install packages 
if (!require("pacman")) install.packages("pacman")

pacman::p_load(# Tidyverse packages including dplyr and ggplot2 
               tidyverse,
               ggthemes,
               ltmle,
               tmle,
               SuperLearner,
               tidymodels,
               caret,
               e1071,
               rpart,
               furrr,
               parallel,
               ranger)

set.seed(44)
```

# Introduction

For our final lab, we will be looking at the [SuperLearner](https://cran.r-project.org/web/packages/SuperLearner/vignettes/Guide-to-SuperLearner.html) library, as well as the [Targeted Maximum Likelihood Estimation (TMLE)](https://www.jstatsoft.org/article/view/v051i13) framework, with an extension to longitudinal data structures. This lab brings together a lot of what we learned about both machine learning and causal inference this year, and serves as an introduction to this intersection!

## Data

For this lab, we will use the Boston dataset from the `MASS` library. This dataset is a frequently used toy dataset for machine learning. The main variables we are going to predict is `medv` which is the median home value for a house in Boston.

```{r}
# Load Boston dataset from MASS package
data(Boston, package = "MASS")
glimpse(Boston)
```

# SuperLearner

First, we are going to introduce the SuperLearner package for machine learning in R. SuperLearner was developed here at Berkeley, and we are going to follow [the guide](https://cran.r-project.org/web/packages/SuperLearner/vignettes/Guide-to-SuperLearner.html) put together by Chris Kennedy. There are some differences, mostly because of the introduction of new machine learning tools like [caret](https://topepo.github.io/caret/) and [tidymodels](https://www.tidymodels.org/). 

The basic idea underlying SuperLearner is that it combines cross-validation with ensemble learning to create a "meta-estimator" that is a weighted combination of constituent algorithms. This idea should sound familiar from when we explored ensemble methods in `sklearn` in Python. 

### Train/Test Split

Let's start with our typical train/test split. There are several options for doing this, but we will use the `tidymodels` method. Let's take a look:

```{r}
# initial_split function from tidymodels/rsample
boston_split <- initial_split(Boston, prop = 3/4)

# Declare the training set with rsample::training()
train <- training(boston_split)
# y_train is medv where medv > 22 is a 1, 0 otherwise
y_train <- train %>% 
  mutate(medv = ifelse(medv > 22, 
                       1,
                       0)) %>%
  pull(medv) 

# x_train is everything but the outcome  
x_train <- train %>%
  select(-medv)

# Do the same procedure with the test set
test <- testing(boston_split)

y_test <- test %>%
  mutate(medv = ifelse(medv > 22, 
                     1,
                     0)) %>%
  pull(medv)

x_test <- test %>%
  select(-medv)
```

### SuperLearner Models

Now that we have our train and test partitions set up, let's see what machine learning models we have available to us. We can use the `listWrappers()` function from SuperLearner:

```{r}
listWrappers()
```
Notice how we have both prediction algorithms for supervised learning, and screening algorithms for feature selection (some may be both).

Let's go ahead and fit a model. We'll start with a LASSO which we can call via `glmnet`:

```{r}
sl_lasso <- SuperLearner(Y = y_train,
                         X = x_train,
                         family = binomial(),
                         SL.library = "SL.glmnet")

sl_lasso
```
Notice how it spits out a "Risk" and a "Coef". The "Coef" here is 1 because this is the only model in our ensemble right now. Risk is essentially a measure of accuracy, in this case something like mean squared error. We can see the model in our ensemble that had the lowest risk like this:

```{r}
# Here is the risk of the best model (discrete SuperLearner winner).
# Use which.min boolean to find minimum cvRisk in list
sl_lasso$cvRisk[which.min(sl_lasso$cvRisk)]
```

### Multiple Models

Now let's extend this framework to multiple models. Within SuperLearner, all we need to do is add models to the `SL.library` argument:

```{r}
sl = SuperLearner(Y = y_train,
                  X = x_train,
                  family = binomial(),
                  SL.library = c('SL.mean',
                                 'SL.glmnet',
                                 'SL.ranger'))
sl
```

Now let's move to our validation step. We'll use the `predict()` function to take our SuperLearner model (only keeping models that had weights) and generate predictions. We can then compare our predictions against our true observations.

```{r}
preds <- predict(sl,
                 x_test,
                 onlySL = TRUE)

# start with y_test
validation <- y_test %>%
  # add our predictions
  bind_cols(preds$pred[,1]) %>%
  # rename columns
  rename(obs = `...1`,
         pred = `...2`) %>%
  mutate(pred = ifelse(pred >= .5, 
                           1,
                           0))

head(validation)
```

Notice that the predictions are not binary 1/0s, but rather probabilities. So, we recode these so that if estimate >= .5 it becomes a 1, and 0 otherwise. We can then use our standard classification metrics and create a confusion matrix using `caret`:

$TP$: True Positives, predicted a 1 and observed a 1
$FP$: False Positives, predicted a 1 and observed a 0
$TN$: True Negatives, predicted a 0 and observed a 0
$FN$: False Negatives, predicted a 0 and observed a 1

```{r}
caret::confusionMatrix(as.factor(validation$pred),
                       as.factor(validation$obs))
```


SuperLearner can take a long time to run, but we can also speed this up with parallelization. Unfortunately this works slightly differently in Windows and Mac/Linux (R doesn't seem to recognize Windows Subsystem for Linux).

```{r}
# Parallel backend Mac/Linux
n_cores <- availableCores() - 1

plan(multiprocess, 
     workers = n_cores) 
set.seed(44, "L'Ecuyer-CMRG")

cv_sl = CV.SuperLearner(Y = y_train, 
                        X = x_train, 
                        family = binomial(),
                          V = 20,
                        parallel = 'multicore',
                        #parallel = cluster,
                          SL.library = c("SL.mean", 
                                         "SL.glmnet", 
                                         "SL.ranger"))
plot(cv_sl)
```

```{r}
# Windows (for SL only, the above should work for tidymodels)
cluster = parallel::makeCluster(availableCores() - 1)
# Load SuperLearner onto all clusters
parallel::clusterEvalQ(cluster, library(SuperLearner))
parallel::clusterSetRNGStream(cluster, 1)
cv_sl = CV.SuperLearner(Y = y_train, X = x_train, family = binomial(),
                          # For a real analysis we would use V = 10.
                          V = 20,
                          parallel = cluster,
                          SL.library = c("SL.mean", 
                                         "SL.glmnet",
                                         "SL.ranger"))
parallel::stopCluster(cluster)
plot(cv_sl)
```

## Targeted Maximum Likelihood Estimation (TMLE)

We're now ready to move to the TMLE framework. TMLE combines machine learning and causal inference by using machine learning (i.e. data-adaptive models) to estimate some quantity of interest (so making inference). The key is that even though machine learning models oftentimes do not have outputs like coefficients, they can still be used to target the estimator (i.e. a regression) to that quantity of interest. This has a few different benefits, the primary one being that this framework creates a **doubly robust** estimator. Double robustness means that if we either:

1. Fit the right model to estimate the expected outcome correctly

OR

2. Fit the model to estimate the probability of treatment correctly

Then the final TMLE estimator will be **consistent**. Consistent means that as the sample size grows to infinity, the bias will drop to 0. We're going to explore this idea in depth. The example we will go through here is drawn from Katherine Hoffman's [blog](https://www.khstats.com/blog/tmle/tutorial-pt2/). She also provides visual guides to [SuperLearner](https://github.com/hoffmakl/causal-inference-visual-guides/blob/master/visual-guides/Superlearner.pdf) and [TMLE](https://github.com/hoffmakl/causal-inference-visual-guides/blob/master/visual-guides/TMLE.pdf).

The basic procedure we will go through is:

1. Estimate the outcome model, $\bar{Q}^{0}_{n}(A, W)$
2. Estimate the probability of treatment model so we can "target" the initial estimate, $g(W) = P(A = 1|W)$ 
3. Extract the "clever covariate" or fluctuation parameter that tells us how to update our initial estimate
4. Update the initial estimate to get $\bar{Q}^{1}_{n}(A, W)$
5. Calculate ATE
6. Calculate confidence intervals

### Step 1: Initial Estimate of the Outcome

The first step in TMLE is to estimate the **outcome model**, or the prediction of our target,$Y$, conditional on the treatment status, $A$ and covariates/features, $W$. We could do this via a classic regression model, but we could also flexibly fit the model using machine learning. In this case, we'll create a SuperLearner ensemble. This $Q$ step gives us our initial estimate. Do the following:

1. Create a SuperLearner library called `sl_libs`
2. Prepare an outcome vector, $Y$ and treatment/covariate matrix, $W_A$
3. Fit the SuperLearner model for the $Q$ step to obtain an initial estimate of the outcome

```{r}
# SuperLearner libraries
sl_libs <- ...

# Prepare data for SuperLearner/TMLE
# Mutate Y, A for outcome and treatment, use tax, age, and crim as covariates
data_obs <- Boston %>%
  mutate(Y = ifelse(medv > 22, 
                       1,
                       0)) %>%
  rename(A = chas) %>%
  select(Y, A, tax, age, crim) 

# Data Prep
# Outcome
Y <- ...
# Covariates
W_A <- ...

# Fit SL for Q step, initial estimate of the outcome
Q <- ...
```

Now that we have trained our model, we need to create predictions for three different scenarios:

1. Predictions assuming every unit had its observed treatment status.
2. Predictions assuming every unit was treated.
3. Predictions assuming every unit was control.

Fill in the code to obtain these predictions.

```{r}
# observed treatment
Q_A <- ...

# if every unit was treated
W_A1 <- ...
Q_1 <- ...

# if everyone was control
W_A0 <- ...
Q_0 <- ...
```

We can take our predictions and put them all into one dataframe:

```{r}
dat_tmle <- tibble(Y = Y, A = W_A$A, Q_A, Q_0, Q_1)
head(dat_tmle)
```

We *could* go ahead and grab our ATE now using G-computation, which is the difference in expected outcomes under treatment and control conditional on covariates. However, the estimate we get below is targeted (optimized the bias-variance tradeoff) at the predictions of the outcome, not the ATE.  

```{r}
ate_gcomp <- mean(dat_tmle$Q_1 - dat_tmle$Q_0)
ate_gcomp
```

## Step 2: Probability of Treatment

Now that we have an initial estimate, we want to "target" it. To do this, we first need to estimate the probability of every unit receiving treatment. This step should look similar to how we estimated the propensity score during matching. Fit a $g$ model using SuperLearner. **Hint**: Think carefully about what should be supplied to the $Y$ and $X$ arguments here.

```{r}
A <- W_A %>% pull(A)
W <- Boston %>% select(tax, age, crim) 

g <- ...
```

Now that we have a model for our propensity score, we can go ahead and calculate both the inverse probability of receiving treatment and the negative inverse probability of not receiving treatment (basically the probability of not receiving treatment). Fill in the code below to obtain both of these quantities. **Hint**: The name "negative inverse probability of not receiving treatment" is a mouthful but should give you a hint about how to set up the calculation.

```{r}
# Prediction for probability of treatment
g_w <- ...

# probability of treatment
H_1 <- ...

# probability of control
H_0 <- ...
```

We can then create the "clever covariate" which assigns the probability of treatment to treated variables, and the probability of control to control variables.  

```{r}
# 
dat_tmle <- # add clever covariate data to dat_tmle
  dat_tmle %>%
  bind_cols(
         H_1 = H_1,
         H_0 = H_0) %>%
  mutate(H_A = case_when(A == ... ~ ..., 
                       A == ... ~ ...))  
```

We now have the initial estimate of the outcome, $Q_A$, and the estimates for the probability of treatment, $H_A$.

### Step 3: Fluctuation Parameter

We are now ready to update our initial estimate, $Q_A$ with the information from our propensity score estimates, $H_A$. We perform this update by fitting a logistic regression where we predict our outcome after passing our initial estiamte, $Q_A$ through a logistic transformation and then fitting a logistic regression (the `-1 + offset()` here is necessary because our intercept term is not constant).

```{r}
glm_fit <- glm(Y ~ -1 + offset(qlogis(Q_A)) + H_A, data=dat_tmle, family=binomial)
```

We can then grab the coefficient from our model:

```{r}
eps <- coef(glm_fit)
```

eps (or epsilon/$\hat{\epsilon}$) is the **fluctuation parameter**. This is the coefficient on our "clever covariate", and basically tells us how much to update our intial model, $Q$ by.

## Step 4: Update Initial Estimates

We can now update the expected outcome for all of observations, conditional on their observed treatment status and their covariates:

```{r}
H_A <- dat_tmle$H_A 
Q_A_update <- plogis(qlogis(Q_A) + eps*H_A)
```

Do the same for outcome under treatment:

```{r}
Q_1_update <- plogis(qlogis(Q_1) + eps*H_1)
```

Do the same for outcome under control:

```{r}
Q_0_update <- plogis(qlogis(Q_0) + eps*H_0)
```

We now have updated expected outcomes for each unit for their actual treatment status, as well as simulated if they were all in treatment and all in control.

## Step 5: Compute the Statistical Estimand of Interest

Fill in the code to calculate the ATE using our updated information for Q:

```{r}
tmle_ate <- ...
tmle_ate
```

## Step 6: Calculate Standard Errors for CIs and p-values

And finally calculate the standard errors and p-values:

```{r}
infl_fn <- (Y - Q_A_update) * H_A + Q_1_update - Q_0_update - tmle_ate
```

```{r}
tmle_se <- ...

conf_low <- ...
conf_high <- ...
pval <- 2 * (1 - pnorm(abs(tmle_ate / tmle_se)))
```

## Via TMLE Package

Thankfully, we do not need to take all of these steps every time we use the TMLE framework. The `tmle()` function handles all of this for us! Notice how we get a similar ATE from running this function:

```{r}
tmle_fit <-
  tmle::tmle(Y = Y, 
           A = A, 
           W = W, 
           Q.SL.library = sl_libs, 
           g.SL.library = sl_libs) 

tmle_fit
```

## LTMLE

One of the main shortcomings of the TMLE framework is that it can only handle baseline covariates (covariates measured before treatment). It also requires that intervention happens at a single time point. The `ltmle` library allows us to relax some of these restrictions so that we can handle time-dependent confounders. The basic setup for the LTMLE function is that we need ot set up our $W$, $A$, and $Y$, and then pass it to the `ltmle()` function: 

```{r}
data_obs_ltmle <- data_obs %>%
  rename(W1 = tax, W2 = age, W3 = crim) %>%
  select(W1, W2, W3, A, Y)

result <- ltmle(data_obs_ltmle, Anodes = "A", Ynodes = "Y", abar = 1)

```

### Single Time Point

Imagine if there was a time ordering to our data, in particular a model like:

$$W1 -> W2 -> W3 -> A -> Y$$

Let's simulate some data that captures this relationship. Notice how we added two arguments here, `Lnodes` and `Sl.library`. `SL.library` should look familiar now, and `Lnodes` refers to a "time varying covariate". For now we're going to leave this as a NULL, but we'll see how to use it soon.

```{r}
rexpit <- function(x) rbinom(n=length(x), size=1, prob=plogis(x))

n <- 1000
W1 <- rnorm(n)
W2 <- rbinom(n, size=1, prob=0.3)   
W3 <- rnorm(n)
A <- rexpit(-1 + 2 * W1 + W3)
Y <- rexpit(-0.5 + 2 * W1^2 + 0.5 * W2 - 0.5 * A + 0.2 * W3 * A - 1.1 * W3)
data <- data.frame(W1, W2, W3, A, Y)

result <- ltmle(data, Anodes="A", Lnodes=NULL, Ynodes="Y", abar=1, SL.library=sl_libs)
```

### Longitudinal Data Structure

Now imagine we instead of a time ordering like this:

$$W -> A1 -> L -> A2 -> Y$$

We can simulate some more data to reflect this structure, and then fit a `ltme()` function. Notice how now we have "L" nodes. In the data structure specified above, we have some baseline covariates that occur before the first treatment, some time dependent covariate that comes after the first treatment but before the second, then a second treatment and then outcome. Notice how we can now add `L` nodes that occur in between the two treatments so that we can deal with this "time-dependent confounding".

```{r}
n <- 1000
W <- rnorm(n)
A1 <- rexpit(W)
L <- 0.3 * W + 0.2 * A1 + rnorm(n)
A2 <- rexpit(W + A1 + L)
Y <- rexpit(W - 0.6 * A1 + L - 0.8 * A2)
data <- data.frame(W, A1, L, A2, Y)

ltmle(data, Anodes=c("A1", "A2"), Lnodes="L", Ynodes="Y", abar=c(1, 1), SL.library = sl_libs)
```

The [`ltmle` vignette](https://github.com/joshuaschwab/ltmle/blob/master/vignettes/ltmle-intro.Rmd) provides even more examples, including for censored data. The main concept here is that `ltmle` allows for causal estimates in observational data in complicated treatment regimes such as staggered adoption, subject dropout, multiple treatments, etc.

## Concluding Thoughts

We have covered a lot of ground this year! To recap:

- Reproducible Data Science
  - GitHub/version control
  - Collaborative data science
- Machine Learning
  - Supervised Learning
    - Regression
    - Classification
  - Unsupervised Learning
    - Dimensionality Reduction
    - Clustering/grouping
- Text Analysis
  - Text preprocessing
  - Dictionary methods, word2vec, sentiment analysis
  - Prediction
- Causal Inference
  - Matching 
  - Regression Discontinuity
  - Diff-in-Diffs/Synthetic Control
  - Sensitivity Analysis
  - SuperLearner/Targeted Maximum Likelihood Estimation

This covers a lot of computational social science! But there's still more. As you're thinking about where to go next, I recommend exploring these areas:

- Computational Tools/Data Acquisition
  - Web scraping (selenium)
  - APIs
  - Bash/CLI
  - XML/HTML parsing (BeautifulSoup)
- High Performance Computing
  - Parallel processing. We mostly covered "embarrassingly parallel" techniques, but there are other more advanced ones as well
  - Amazon Web Services (AWS)/Microsoft Azure cloud computing
  - Secure File Transfer Protocol (SFTP)
- Deep Learning
  - We covered some of the basics but more applications would be good
  - GPU acceleration
  - Deep Learning for text analysis (Bidirectional Encoder Representations from Transformers (BERT))
- Machine Learning and Causal Inference
  - Meta-estimators (like TMLE)
  - Heterogeneous Treatment Effects
  

# Appendix for SL & LTMLE 

a)  We can now plot our [AUC-ROC curve](https://en.wikipedia.org/wiki/Receiver_operating_characteristic):

$$Sensitivity = True Positive Rate = Recall = \frac{TP}{TP + FN}$$ 
$$Specificity = True Negative Rate = \frac{TN}{TN + FP}$$ 

```{r}
roc_df <- roc_curve(validation,
          pred,
          truth = as.factor(obs))

roc_df %>%
  ggplot() + 
  geom_point(aes(x = specificity, y = 1 - sensitivity)) +
  geom_line(aes(x = specificity, y = 1 - sensitivity)) + 
  theme_fivethirtyeight() +
  theme(axis.title = element_text()) +
  ggtitle('AUC-ROC Curve for SuperLearner') +
  xlab('Specificity') +
  ylab('Sensitivity')
```

